# Курсовая работа по курсу от Мегафон

### Определение вероятности подключения услуг



## Использование:

### Запуск из-под docker: 


#### Построение docker-образа (на базе python 3.7 со всеми зависимостями из requirements.txt): 

```
docker build -t nnn/megafon_project .
```

#### Запуск 

```
./run.sh
```

Или явное использование docker run по мотивам ./run.sh (одна строка).

После запуска должен появиться data/answers_test.csv

run.sh прозрачно передает все параметры в luigi.  run.sh использует local scheduler.  run.sh использует тэг docker-образа nnn/megafon_project.

Для запуска не из под docker надо обеспечить установку всех нужных пакетов python из requirements.txt

Файлы с данными подключаются к исполнению в run.sh через docker bind mounts (-v) поддиректорий data и model , поэтому все пути в параметрах должны указывать на содержимое внутри этих директорий. Для использования других путей модифицируйте параметры -v


### Детали:

Сохраненная модель, обученная на всем наборе: model/default.pkl

Для предсказания нужны:

* файл с id, vas_id, buy_time (параметр luigi input_path, по умолчанию data/data_test.csv)
* файл  features.csv (параметр luigi features_path, по умолчанию data/features.csv)
* файл с обученной моделью  (параметр luigi pipeline_path, по умолчанию model/default.pkl)

Главная задача в luigi: LTaskPredict

Параметры:

 * data_dir - Базовая директория для данных, все промежуточные файлы сохраняются там. По умолчанию ./data.
 * input_path - Файл с входными данными для предсказаний, без доп. признаков. По умолчанию <data_dir>/data_test.csv.
 * features_path - Файл с дополнительными признаками для предсказаний. По умолчанию <data_dir>/features.csv.
 * output_path - Файл результата. По умолчанию <data_dir>/answers_test.csv.
 * pipeline_path - Pickle-файл с пайплайном модели. По умолчанию model/default.pkl.
 * threshold - Порог вероятности для предсказания target=1. По умолчанию 0.2.

Поскольку для предсказаний необходимо примержить огромный файл с признаками, в предсказании есть длительный (несколько минут) этап загрузки и примерживания этого файла. Эта операция разбита на 2 под-задачи:

 * LTaskIndexFeatures - выделение "индекса" - датафрейма с колонкамим id и buy_time для поиска ближайшего через pandas.merge_asof
 * LTaskAddFeatures - непосредственно примерживание фич, с использованием индекса, составленного в LTaskIndexFeatures


Код обучения и некоторых экспериментов, а также тестовый запуск пайплайна luigi - в notebook.ipynb

В качестве финального классификатора выбран CatBoostClassifier. 

Уменьшение набора фич и выделение большого набора категориальных фич (кроме vas_id) особого эффекта на валидации не давали, как и особого выигрыша в скорости. 

Для валидации используются последние по времени val_portion записей из train (задано 10%). Для обучения финальной модели используется весь train.

Результаты на валидации:

```
y_pred = y_proba > 0.12244897959183673
F1-score: 0.4578827408952039
F1-score-macro: 0.69058119173769
ROC-AUC-score: 0.8431906123005778
              precision    recall  f1-score   support

         0.0       0.98      0.87      0.92     77100
         1.0       0.32      0.78      0.46      6066

    accuracy                           0.87     83166
   macro avg       0.65      0.83      0.69     83166
weighted avg       0.93      0.87      0.89     83166

```

В качестве порога для финальной модели выбран 0.2 (параметр threshold в LTaskPredict).




